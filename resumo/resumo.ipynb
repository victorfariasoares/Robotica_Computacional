{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dac1eb7",
   "metadata": {},
   "source": [
    "# Módulo 1 - Introdução ao Curso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e853790c",
   "metadata": {},
   "source": [
    "## Classes em Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dbd2f8",
   "metadata": {},
   "source": [
    "Criamos classes em python para construir objetos que tem as mesmas características. Esses objetos são chamados de instâncias de cada classe.\n",
    "<br>\n",
    "<br>\n",
    "Toda classe deve ter como primeira função o \"__init__\". Essa função vai definir todas as caracteríticas (atributos) minimas que uma instância daquela classe deve ter.\n",
    "<br>\n",
    "<br>\n",
    "Depois de criar o \"__init__\" daí podemos criar as outras funções que poderão fazer outras coisas com as nossas instâncias.\n",
    "<br>\n",
    "<br>\n",
    "**Todas as classes em python devem possuir atributos que são suas características e devem possuir métodos que são as coisas que ela pode fazer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71b0b7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exemplo da aula:\n",
    "\n",
    "class Carro:\n",
    "    def __init__(self, cor, marca, modelo, ano):\n",
    "        self.cor = cor\n",
    "        self.marca = marca\n",
    "        self.modelo = modelo\n",
    "        self.ano = ano\n",
    "\n",
    "    def acelerar(self):\n",
    "        print(\"O carro está acelerando.\")\n",
    "\n",
    "    def frear(self):\n",
    "        print(\"O carro está freando.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a494bb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vermelho\n",
      "O carro está acelerando.\n"
     ]
    }
   ],
   "source": [
    "# Vamos criar uma instância da classe Carro. Como passamos no init 4 argumentos, então precisamos de pelo menos 4\n",
    "# argumentos para definir uma nova instância de Carro.\n",
    "\n",
    "Meu_carro = Carro(\"Vermelho\", \"Ferrari\", \"458 Italia\", 2020)\n",
    "\n",
    "#Criamos uma intância de Carro com o nome \"Meu_carro\"\n",
    "\n",
    "#Vamos fazer o carro usar as outras funções da classe:\n",
    "\n",
    "print(Meu_carro.cor)  # Saída: Vermelho\n",
    "Meu_carro.acelerar()  # Saída: O carro está acelerando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe329a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos melhorar essa nossa classe para que a função init aceite somente os argumentos desejados\n",
    "class Carro:\n",
    "    def __init__(self, cor: str, marca: str, modelo: str, ano: int):\n",
    "        self.cor = cor\n",
    "        self.marca = marca\n",
    "        self.modelo = modelo\n",
    "        self.ano = ano\n",
    "\n",
    "    def acelerar(self):\n",
    "        print(\"O carro está acelerando.\")\n",
    "\n",
    "    def frear(self):\n",
    "        print(\"O carro está freando.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7391a09d",
   "metadata": {},
   "source": [
    "### Métodos estáticos (@staticmethod)\n",
    "\n",
    "Métodos estáticos são métodos que pertencem a classe a que estão inseridos porém não pertencem a nenhuma instância, ou seja, não usa nenhum self. Justamente por não usar o parâmetro self, métodos estáticos não podem acessar atributos da classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e9b271",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exemplo:\n",
    "class Carro:\n",
    "    def __init__(self, cor: str, marca: str, modelo: str, ano: int):\n",
    "        self.cor = cor\n",
    "        self.marca = marca\n",
    "        self.modelo = modelo\n",
    "        self.ano = ano\n",
    "\n",
    "    def acelerar(self):\n",
    "        print(\"O carro está acelerando.\")\n",
    "\n",
    "    def frear(self):\n",
    "        print(\"O carro está freando.\")\n",
    "\n",
    "    \n",
    "    @staticmethod    \n",
    "    def numero_de_rodas():\n",
    "        print(\"O carro possui 4 rodas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c017884",
   "metadata": {},
   "source": [
    "### Herança de Classes\n",
    "Em Python, uma classe pode herdar de outra classe. O uso de herança permite que a classe filha tenha todos os atributos e métodos da classe pai, além de poder adicionar, ou modificar os atributos e métodos.\n",
    "<br>\n",
    "<br>\n",
    "Na nossa classe abaixo, como a classe Caminhão, que herda de Carro, possui todos os atributos que a classe Carro possui, então usamos o \"super().__init__()\" para declarar os métodos que já tinham na outra classe e queremos manter nessa nova classe. Isso faz com que não precisemos ficar colocando toda hora \"self.cor, self.marca.....\".\n",
    "<br>\n",
    "<br>\n",
    "Só precisamos colocar o self explicitamente para o atributo novo que vem no init da classe Caminhão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "755b100c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O carro está acelerando.\n",
      "O carro possui 4 rodas\n",
      "Carregando 15 toneladas no caminhão.\n",
      "O caminhão possui 6 rodas.\n"
     ]
    }
   ],
   "source": [
    "# Classe filha Caminhao que herda de Carro\n",
    "class Caminhao(Carro):\n",
    "    def __init__(self, cor: str, marca: str, modelo: str, ano: int, capacidade_carga: int):\n",
    "        super().__init__(cor, marca, modelo, ano)  # Chama o construtor da classe pai\n",
    "        self.capacidade_carga = capacidade_carga  # Atributo adicional\n",
    "\n",
    "    def carregar(self, carga: int):\n",
    "        if carga <= self.capacidade_carga:\n",
    "            print(f\"Carregando {carga} toneladas no caminhão.\")\n",
    "        else:\n",
    "            print(\"Carga excede a capacidade máxima do caminhão!\")\n",
    "\n",
    "    # Sobrescrevendo o numero de rodas\n",
    "    @staticmethod\n",
    "    def numero_de_rodas():\n",
    "        print(\"O caminhão possui 6 rodas.\")\n",
    "\n",
    "    # Sobrescrevendo o método frear\n",
    "\n",
    "# Exemplo de uso\n",
    "carro = Carro(\"Vermelho\", \"Toyota\", \"Corolla\", 2020)\n",
    "caminhao = Caminhao(\"Azul\", \"Volvo\", \"FH16\", 2021, 20)\n",
    "\n",
    "carro.acelerar()\n",
    "carro.numero_de_rodas()\n",
    "caminhao.carregar(15)\n",
    "caminhao.numero_de_rodas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e109e6",
   "metadata": {},
   "source": [
    "## Funções através de dicionários\n",
    "\n",
    "O dicionário que temos dentro da funçção init, organiza o comportamento do robo. Cada estado é uma função que o robo deve executar. A chave do dicionário é o nome do estado e o valor é a função que deve ser executada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e08f4448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estado atual: forward\n",
      "O robô está indo para frente\n",
      "\n",
      "Estado atual: forward\n",
      "O robô está indo para frente\n",
      "\n",
      "Estado atual: left\n",
      "O robô está indo para esquerda\n",
      "\n",
      "Estado atual: right\n",
      "O robô está indo para direita\n",
      "\n",
      "Estado atual: stop\n",
      "O robô está parado\n"
     ]
    }
   ],
   "source": [
    "class Robot:\n",
    "    def __init__(self):\n",
    "        self.robot_state = 'stop'\n",
    "        self.state_machine = {\n",
    "            'forward': self.forward,\n",
    "            'left': self.left,\n",
    "            'right': self.right,\n",
    "            'stop': self.stop,\n",
    "        }\n",
    "\n",
    "    def forward(self):\n",
    "        print(f'\\nEstado atual: {self.robot_state}')\n",
    "        print('O robô está indo para frente')\n",
    "\n",
    "    def left(self):\n",
    "        # Move subtraindo 1 uma coluna\n",
    "        # Atualiza a posição\n",
    "        print(f'\\nEstado atual: {self.robot_state}')\n",
    "        print('O robô está indo para esquerda')\n",
    "\n",
    "    def right(self):\n",
    "        # Move somando 1 uma coluna\n",
    "        # Atualiza a posição\n",
    "        print(f'\\nEstado atual: {self.robot_state}')\n",
    "        print('O robô está indo para direita')\n",
    "\n",
    "    def stop(self):\n",
    "        # Não faz nada\n",
    "        print(f'\\nEstado atual: {self.robot_state}')\n",
    "        print('O robô está parado')\n",
    "\n",
    "    def control(self):\n",
    "        self.state_machine[self.robot_state]()\n",
    "\n",
    "robot = Robot()\n",
    "sequencia = ['forward', 'forward', 'left', 'right', 'stop']\n",
    "for robot_state in sequencia:\n",
    "    robot.robot_state = robot_state\n",
    "    robot.control()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d5b73a",
   "metadata": {},
   "source": [
    "A variavel self.robot_state é uma string que contem o nome do estado atual do robo. Para executar a função que corresponde ao estado atual, basta fazer:\n",
    "\n",
    "        ***self.state_machine[self.robot_state]()***\n",
    "Nesse caso, modificamos o valor da variavel self.robot_state de fora da classe, mas poderiamos ter feito isso dentro da classe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa936472",
   "metadata": {},
   "source": [
    "**self.robot_state** é o estado atual do robô\n",
    "<br>\n",
    "**self.state_machine** é um dicionário que mapeia os estados para as funções que devem ser executadas\n",
    "<br>\n",
    "**self.control()** é a função que executa a máquina de estados<br>\n",
    "**self.state_machine [self.robot_state] ()** executa a função correspondente ao estado atual do robô<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd3931b",
   "metadata": {},
   "source": [
    "# Módulo 2 - Introdução à ROS 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e80fa4a9-3d7a-4e70-b8f3-035c14410dfb",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (715721359.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\victo\\AppData\\Local\\Temp\\ipykernel_30016\\715721359.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    ros2 launch my_gazebo pista-23B.launch.py\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## Para rodar a pista \n",
    "ros2 launch my_gazebo pista-23B.launch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07792008",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "## Executando a câmera\n",
    "ros2 run rqt_image_view rqt_image_view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f96b318",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "## Para operar o robô pelo teclado\n",
    "ros2 run turtlebot3_teleop teleop_keyboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62c7279",
   "metadata": {},
   "source": [
    "### Tópicos e Mensagens\n",
    "\n",
    "**Nodes (Nós):** Um nó é um processo que executa uma tarefa especifica na ROS. No nosso caso, um nó é um script python que vamos chamar diretamente.\n",
    "\n",
    "**Topics (Tópicos):** Os tópicos na ROS são barramentos onde a informação é trocada entre nós. Através de tópicos, nós podemos publicar e se inscrever para enviar e receber mensagens. Quando um nó publica uma mensagem ela é enviada para todos os nós que estão inscritos nesta mensagem. Tópicos são identificados por strings únicas.\n",
    "\n",
    "**Messages (Mensagens):** As mensagens são estruturas de dados que carregam informações. Elas são podem ser compostas por tipos primitivos, como inteiros, floats, strings, etc. ou por outras mensagens. As mensagens são usadas para publicar e receber informações nos tópicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026bd74d",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "## Para ver a lista de tópicos \n",
    "ros2 topic list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cbe462",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "## Listar o tipo de mensagem (retorna o tipo de msg que o tópico transporta)\n",
    "ros2 topic info {\"Nome do Tópico\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffecc8d",
   "metadata": {},
   "source": [
    "Quando mandamos o comando acima, recebemos o seguinte output:\n",
    "<br>\n",
    "***Type: geometry_msgs/msg/Twist<br>\n",
    "Publisher count: 1<br>\n",
    "Subscription count: 1*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e647c7",
   "metadata": {},
   "source": [
    "Type: geometry_msgs/msg/Twist - Esse é o tipo de mensagem que o tópico transporta, no caso, uma mensagem do tipo Twist que existe dentro do pacote geometry_msgs.\n",
    "\n",
    "Publisher count: 1 - Quantidade de nós que estão publicando mensagens neste tópico.\n",
    "\n",
    "Subscription count: 1 - Quantidade de nós que estão inscritos neste tópico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42715578",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "## Visualizar Mensagem (retorna as msg que estão sendo publicadas no tópico)\n",
    "ros2 topic echo {\"Nome do Tópico\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1929edde",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "## Visualizando a Estrutura das mensagens \n",
    "ros2 interface show  {\"Nome do Pacote\"}/msg/{\"Nome da Mensagem\"}\n",
    "## EX: ros2 interface show geometry_msgs/msg/Twist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1124a8c",
   "metadata": {},
   "source": [
    "### Criando pacotes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686d7c1e",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "## No terminal\n",
    "cd ~/colcon_ws/src\n",
    "ros2 pkg create --build-type ament_python \"Nome do pacote\" --dependencies rclpy std_msgs geometry_msgs my_package\n",
    "ros2 pkg create --build-type ament_python \"avaliacao_af\" --dependencies rclpy std_msgs geometry_msgs my_package\n",
    "\n",
    "# O primeiro comando muda o diretório atual para a pasta src do workspace colcon_ws, \n",
    "## é nessa pasta que todos os pacotes da ROS 2 são criados.\n",
    "\n",
    "\n",
    "\n",
    "# pkg create --> comando para criar um novo pacote\n",
    "\n",
    "#--build-type ament_python --> o tipo de pacote que será criado, nesse caso, um pacote em Python\n",
    "\n",
    "# --dependencies rclpy std_msgs geometry_msgs --> são as dependências do pacote que será criado, nesse caso, \n",
    "## o pacote depende do rclpy, std_msgs e geometry_msgs e my_package é um pacote externo que foi criado anteriormente\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f58461",
   "metadata": {},
   "source": [
    "### Compilando pacotes\n",
    "\n",
    "Após criar pacotes, precisamos compilá-los. Para isso é só digitar no terminal:\n",
    "\n",
    "***cb*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0465e53",
   "metadata": {},
   "source": [
    "## Criando um Publisher e um Subscriber na ROS 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824bf937",
   "metadata": {},
   "source": [
    "## Criando um publisher\n",
    "\n",
    "Quando vamos criar um nó para ROS2, normalmente criamos no seguinte caminho: ***cd ~/colcon_ws/src/my_package***\n",
    "<br>\n",
    "O processo de criar é o seguinte:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ea466",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "touch first_node.py ## cria o arquivo first_node.py\n",
    "chmod +x *.py       # Dá permissão de execução para todos os arquivos Python da pasta. Este comando é necessário\n",
    "                    # Para que o ROS consiga executar o arquivo Python como um nó ROS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc50b33c",
   "metadata": {},
   "source": [
    "Feito isso, podemos no arquivo criado adicionar o código. \n",
    "EXEMPLO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4afc807",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f604803",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from geometry_msgs.msg import Twist\n",
    "from nav_msgs.msg import Odometry\n",
    "from rclpy.qos import ReliabilityPolicy, QoSProfile\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "ros2 launch my_package first_node.launch.py\n",
    "\"\"\"\n",
    "\n",
    "class FirstNode(Node):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__('first_node') #Cria um nó com o nome \"first_node\"\n",
    "        self.vel_pub = self.create_publisher(Twist, 'cmd_vel', 10)\n",
    "        # Twist é o tipo da mensagem a ser publicada;\n",
    "        # cmd_vel é o nome do tópico que será publicado\n",
    "        # 10 é o tamanho da fila de mensagens. É um argumento opcional e o valor padrão é 10.\n",
    "\n",
    "        self.timer = self.create_timer(0.25, self.control)\n",
    "        # 0.25 é o tempo entre execuções da função que será executada e foi mencionada ao lado (self.control) \n",
    "\n",
    "    def control(self):\n",
    "        self.twist = Twist()\n",
    "        self.twist.linear.x = -0.2\n",
    "\n",
    "        self.vel_pub.publish(self.twist)\n",
    "    # Função que será executada a cada 0.25 segundos, criando uma msg do tipo Twist, alterando a velocidade linear e\n",
    "    # publicando no tópico cmd_vel (evidenciado na ultima linha do init)\n",
    "\n",
    "\n",
    "def main(args=None):\n",
    "    rclpy.init(args=args) # inicializa o módulo rclpy (ROS Client Library for Python).\n",
    "    first_node = FirstNode() # Cria uma instância da classe FirstNode\n",
    "\n",
    "    rclpy.spin(first_node) # mantém o nó em execução até que ele seja finalizado.\n",
    "\n",
    "\n",
    "\n",
    "    first_node.destroy_node() #finaliza o nó\n",
    "    rclpy.shutdown() #finaliza o módulo rclpy\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b7059e",
   "metadata": {},
   "source": [
    "** para rodar um nó precisamos fazer duas coisas:\n",
    "- Criar um arquivo launch.\n",
    "- Configurar o arquivo ***setup.py*** para que a ROS consiga encontrar o nó"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d603709",
   "metadata": {},
   "source": [
    "## Criando um arquivo Launch\n",
    "\n",
    "Vamos criar um arquivo launch chamado ***first_node.launch.py*** dentro da pasta ***launch*** do pacote ***my_package***. Este arquivo será responsável por iniciar o nó ***first_node.py***.\n",
    "\n",
    "No ***first_node.launch.py***  <br> vamos add o seguinte código:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95535ddb",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "from launch import LaunchDescription\n",
    "from launch_ros.actions import Node\n",
    "\n",
    "def generate_launch_description():\n",
    "    return LaunchDescription([\n",
    "        Node(\n",
    "            package='my_package',\n",
    "            executable='first_node',\n",
    "            output='screen'),\n",
    "    ],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320db434",
   "metadata": {},
   "source": [
    "Node recebe três argumentos:\n",
    "\n",
    "- ***package='my_package'***: nome do pacote que contém o nó.\n",
    "\n",
    "- ***executable='first_node'***: nome do nó que será executado.\n",
    "\n",
    "- ***output='screen'***: imprime a saída do nó no terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eef384",
   "metadata": {},
   "source": [
    "## Configurando o Arquivo setup.py (Para que o ROS consiga encontrar o nó)\n",
    "\n",
    "Vamos add o seguinte código no ***setup.py***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa92e0c",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "from setuptools import setup\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "package_name = 'my_package'\n",
    "\n",
    "setup(\n",
    "    name=package_name,\n",
    "    version='0.0.0',\n",
    "    packages=[package_name],\n",
    "    data_files=[\n",
    "        ('share/ament_index/resource_index/packages',\n",
    "            ['resource/' + package_name]),\n",
    "        ('share/' + package_name, ['package.xml']),\n",
    "        (os.path.join('share', package_name), glob('launch/*.launch.py'))#add todos os arquivos launch da pasta launch ao pacote\n",
    "    ],\n",
    "    install_requires=['setuptools'],\n",
    "    zip_safe=True,\n",
    "    maintainer='somebody very awesome',\n",
    "    maintainer_email='user@user.com',\n",
    "    description='TODO: Package description',\n",
    "    license='TODO: License declaration',\n",
    "    tests_require=['pytest'],\n",
    "    entry_points={\n",
    "        'console_scripts': [\n",
    "            'first_node = my_package.first_node:main', #cria um comando chamado first_node que executa a função\n",
    "            # main do arquivo first_node.py.\n",
    "\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "# Toda vez que fizermos um Node novo, temos que add ele assim como fizemos na linha acima no console_scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5f7c6c",
   "metadata": {},
   "source": [
    "#### Para rodar o que acabamos de criar:\n",
    "\n",
    "***ros2 launch my_package first_node.launch.py***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c557676f",
   "metadata": {},
   "source": [
    "## Arquivos de Base para criação de Nó e Nó Base de Controle:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcace45",
   "metadata": {},
   "source": [
    "### Nó Base\n",
    "\n",
    "Este script é útil para criar um nó que se inscreve em um tópico e executa uma função a cada nova mensagem recebida, publicando uma mensagem em outro tópico.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c7b2c",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from rclpy.qos import ReliabilityPolicy, QoSProfile\n",
    "# Adicione aqui os imports necessários\n",
    "\n",
    "class BaseNode(Node): # Mude o nome da classe\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__('base_node') # Mude o nome do nó\n",
    "        self.timer = self.create_timer(0.25, self.control)\n",
    "\n",
    "        # Inicialização de variáveis\n",
    "\n",
    "        # Subscribers\n",
    "        ## Coloque aqui os subscribers\n",
    "\n",
    "        # Publishers\n",
    "        ## Coloque aqui os publishers\n",
    "\n",
    "    def control(self):\n",
    "        print('running...')\n",
    "\n",
    "\n",
    "def main(args=None):\n",
    "    rclpy.init(args=args)\n",
    "    ros_node = BaseNode() # Mude o nome da classe\n",
    "\n",
    "    rclpy.spin(ros_node)\n",
    "\n",
    "    ros_node.destroy_node()\n",
    "    rclpy.shutdown()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132d057a",
   "metadata": {},
   "source": [
    "### Base Control\n",
    "Neste script, definimos a máquina de estados do robô (no dicionário self.state_machine), o estado inicial (no atributo self.robot_state) e a função de controle (no método self.control()), que a cada 0,25 segundos, executa a função self.state_machine[self.robot_state]() e publica a ação de controle no tópico cmd_vel (self.cmd_vel_pub.publish(self.twist)).\n",
    "\n",
    "Dica: Em uma máquina de estados bem definida, a função de controle não precisa ser alterada, sendo ela a única função que publica no tópico cmd_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1183b10",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from rclpy.qos import ReliabilityPolicy, QoSProfile\n",
    "from geometry_msgs.msg import Twist\n",
    "# Adicione aqui os imports necessários\n",
    "\n",
    "class BaseControlNode(Node): # Mude o nome da classe\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__('base_control_node') # Mude o nome do nó\n",
    "        self.timer = self.create_timer(0.25, self.control)\n",
    "\n",
    "        self.robot_state = 'stop'\n",
    "        self.state_machine = {\n",
    "            'stop': self.stop\n",
    "\n",
    "\n",
    "        }\n",
    "\n",
    "        # Inicialização de variáveis\n",
    "        self.twist = Twist()\n",
    "\n",
    "        # Subscribers\n",
    "        ## Coloque aqui os subscribers\n",
    "\n",
    "\n",
    "        # Publishers \n",
    "\n",
    "        self.cmd_vel_pub = self.create_publisher(Twist, cmd_vel, 10)\n",
    "        ## Coloque aqui os publishers\n",
    "\n",
    "    def stop(self):\n",
    "        self.twist = Twist()\n",
    "\n",
    "    def control(self):\n",
    "        self.twist = Twist()\n",
    "        print(f'Estado Atual: {self.robot_state}')\n",
    "        self.state_machine[self.robot_state]()\n",
    "\n",
    "        self.cmd_vel_pub.publish(self.twist)\n",
    "\n",
    "\n",
    "def main(args=None):\n",
    "    rclpy.init(args=args)\n",
    "    ros_node = BaseControlNode() # Mude o nome da classe\n",
    "\n",
    "    rclpy.spin(ros_node)\n",
    "\n",
    "    ros_node.destroy_node()\n",
    "    rclpy.shutdown()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d23735",
   "metadata": {},
   "source": [
    "## Criando um Subscriber\n",
    "Exemplo de código abaixo usa a mesma base apresentada acima, mas coloquei o código inteiro somente pra ver algumas outras funções que podem ser uteis. Como o odom_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc59dcbf",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from nav_msgs.msg import Odometry\n",
    "from rclpy.qos import ReliabilityPolicy, QoSProfile\n",
    "\n",
    "class SecondNode(Node):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__('second_node')\n",
    "        self.timer = self.create_timer(0.25, self.control)\n",
    "\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "\n",
    "        self.odom_sub = self.create_subscription(\n",
    "            Odometry, #Tipo de mensagem que será recebida\n",
    "            '/odom',  # Nome do tópico que será inscrito\n",
    "            self.odom_callback, #Função que será executada quando uma mensagem for recebida\n",
    "            QoSProfile(depth=10, reliability=ReliabilityPolicy.RELIABLE)) # Configura a qualidade do serviço, é opcional\n",
    "\n",
    "    def odom_callback(self, data: Odometry): #coleta a posição x e y do robô a partir da mensagem recebida.\n",
    "        self.x = data.pose.pose.position.x\n",
    "        self.y = data.pose.pose.position.y\n",
    "\n",
    "    def control(self): #imprime a posição x e y do robô no terminal.\n",
    "        print(f'Posição x: {self.x}')\n",
    "        print(f'Posição y: {self.y}\\n')\n",
    "\n",
    "\n",
    "def main(args=None):\n",
    "    rclpy.init(args=args)\n",
    "    second_node = SecondNode()\n",
    "\n",
    "    rclpy.spin(second_node)\n",
    "\n",
    "    second_node.destroy_node()\n",
    "    rclpy.shutdown()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "Ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06a6141",
   "metadata": {},
   "source": [
    "Com o arquivo configurado, ainda devemos add no setup.py, dentro do dicionário \"entry_points\", na chave \"console_scripts\" o seguinte: \n",
    "<br>\n",
    "<br>\n",
    "***'second_node = my_package.second_node:main',***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39e9891",
   "metadata": {},
   "source": [
    "### Dica!!\n",
    "\n",
    "Na APS 2. Ele nos pediu para criar um subscriber que se inscrevesse no tópico publisher do tipo \"std_msgs/String\". Porém uma coisa não foi dita em detalhes.\n",
    "\n",
    "A estrutura da mensagem do tipo String é **string data**. O conteúdo da mensagem é armazenado na variável **data**. Então para acessar o conteúdo, deve-se utilizar **msg.data**. Depois pode separar o tempo do contador utilizando o comando **msg.data.split()**.\n",
    "\n",
    "Portanto, no \"odom_callback\" foi feito o seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db92d9",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "def odom_callback(self, data: String):\n",
    "        self.mensagem = data.data\n",
    "        string_msg = self.mensagem.split()\n",
    "        self.contador = string_msg[1]\n",
    "        time = int(string_msg[0])\n",
    "        self.df_time = (self.get_clock().now().to_msg().nanosec - time) / (10**9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd790a0e",
   "metadata": {},
   "source": [
    "# Módulo 3 - Controlando o Robô"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c90541",
   "metadata": {},
   "source": [
    "### Entendendo a Odometria(odom)\n",
    "Odometria é a estimativa da posição e orientação de um robô móvel utilizando dados de sensores. Estes atributos são chamados de Pose, que é a posição e orientação do robô no espaço."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c42230",
   "metadata": {},
   "source": [
    "## Tópico de Odometria \n",
    "\n",
    "Se jogarmos no terminal com o simulador e o teleop abertos o comando: ***ros2 interface show nav_msgs/msg/Odometry*** veremos a seguinte mensagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f95a018",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# This represents an estimate of a position and velocity in free space.\n",
    "# The pose in this message should be specified in the coordinate frame given by header.frame_id\n",
    "# The twist in this message should be specified in the coordinate frame given by the child_frame_id\n",
    "\n",
    "# Includes the frame id of the pose parent.\n",
    "std_msgs/Header header\n",
    "\tbuiltin_interfaces/Time stamp\n",
    "\t\tint32 sec\n",
    "\t\tuint32 nanosec\n",
    "\tstring frame_id\n",
    "\n",
    "# Frame id the pose points to. The twist is in this coordinate frame.\n",
    "string child_frame_id\n",
    "\n",
    "# Estimated pose that is typically relative to a fixed world frame.\n",
    "geometry_msgs/PoseWithCovariance pose\n",
    "\tPose pose\n",
    "\t\tPoint position\n",
    "\t\t\tfloat64 x\n",
    "\t\t\tfloat64 y\n",
    "\t\t\tfloat64 z\n",
    "\t\tQuaternion orientation\n",
    "\t\t\tfloat64 x 0\n",
    "\t\t\tfloat64 y 0\n",
    "\t\t\tfloat64 z 0\n",
    "\t\t\tfloat64 w 1\n",
    "\tfloat64[36] covariance\n",
    "\n",
    "# Estimated linear and angular velocity relative to child_frame_id.\n",
    "geometry_msgs/TwistWithCovariance twist\n",
    "\tTwist twist\n",
    "\t\tVector3  linear\n",
    "\t\t\tfloat64 x\n",
    "\t\t\tfloat64 y\n",
    "\t\t\tfloat64 z\n",
    "\t\tVector3  angular\n",
    "\t\t\tfloat64 x\n",
    "\t\t\tfloat64 y\n",
    "\t\t\tfloat64 z\n",
    "\tfloat64[36] covariance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a3a2a3",
   "metadata": {},
   "source": [
    "### Entendendo a mensagem:\n",
    "\n",
    "***pose.pose.position***: A posição do robô no espaço. No caso do simulador, a origem do sistema de coordenadas é o centro da pista (encontro das linhas RGB - XYZ). No caso do robô real, a origem do sistema de coordenadas é estabelecida quando ele começa a se mover - portanto manualmente mover o robô, significa mover a origem do sistema de coordenadas.\n",
    "\n",
    "***pose.pose.orientation***: A orientação do robô no espaço.\n",
    "\n",
    "***twist.twist.linear***: A velocidade linear do robô no espaço. Aqui podemos ver um exemplo entre local e global. Por limitações de hardware, a velocidade linear local do robô só tem uma direção, para frente (eixo-X). No entanto, a velocidade linear global pode ter qualquer direção, no plano XY.\n",
    "\n",
    "***twist.twist.angular***: A velocidade angular do robô no espaço. Neste caso, a velocidade angular local e global são iguais, pois o robô só pode girar em torno do eixo Z."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d46de2e",
   "metadata": {},
   "source": [
    "### Função para conversão de quaternion para ângulos Euler(utilizada dentro do odom_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler_from_quaternion(self, quaternion):\n",
    "            \"\"\"\n",
    "            Converts quaternion (w in last place) to euler roll, pitch, yaw\n",
    "            quaternion = [x, y, z, w]\n",
    "            Below should be replaced when porting for ROS2 Python tf_conversions is done.\n",
    "            \"\"\"\n",
    "            x = quaternion[0]\n",
    "            y = quaternion[1]\n",
    "            z = quaternion[2]\n",
    "            w = quaternion[3]\n",
    "\n",
    "            sinr_cosp = 2 * (w * x + y * z)\n",
    "            cosr_cosp = 1 - 2 * (x * x + y * y)\n",
    "            roll = np.arctan2(sinr_cosp, cosr_cosp)\n",
    "\n",
    "            sinp = 2 * (w * y - z * x)\n",
    "            pitch = np.arcsin(sinp)\n",
    "\n",
    "            siny_cosp = 2 * (w * z + x * y)\n",
    "            cosy_cosp = 1 - 2 * (y * y + z * z)\n",
    "            yaw = np.arctan2(siny_cosp, cosy_cosp)\n",
    "\n",
    "            return roll, pitch, yaw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86feefa",
   "metadata": {},
   "source": [
    "## Entendendo o Laser\n",
    "\n",
    "Jogando os seguintes comandos:\n",
    "<br>\n",
    "<br>\n",
    "***ros2 topic info /scan***\n",
    "<br>\n",
    "<br>\n",
    "***ros2 interface show sensor_msgs/msg/LaserScan***\n",
    "<br>\n",
    "<br>\n",
    "***ros2 topic echo /scan***\n",
    "<br>\n",
    "<br>\n",
    "Obtemos a seguinte mensagem:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f4fa4e",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "header: \n",
    "  seq: 7\n",
    "  stamp: \n",
    "    secs: 808\n",
    "    nsecs: 154000000\n",
    "  frame_id: \"base_scan\"\n",
    "angle_min: 0.0\n",
    "angle_max: 6.28318977355957\n",
    "angle_increment: 0.017501922324299812\n",
    "time_increment: 0.0\n",
    "scan_time: 0.0\n",
    "range_min: 0.11999999731779099\n",
    "range_max: 3.5\n",
    "ranges: [inf, inf, inf, ...]\n",
    "intensities: [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9c5c8",
   "metadata": {},
   "source": [
    "**header**: Cabeçalho da mensagem, que contém informações como o tempo de envio da mensagem e o frame de referência.\n",
    "\n",
    "**angle_min**: 0.0: Ângulo inicial do sensor. O valor 0.0 corresponde a leiura do sensor diretamente para frente do robô.\n",
    "\n",
    "**angle_max**: 6.28...: Ângulo final do sensor. O valor 6.28... equivale a uma volta completa (360 graus).\n",
    "\n",
    "**angle_increment:** 0.017...: Incremento angular entre cada leitura do sensor. O valor 0.017... equivale a um ângulo de 1 grau.\n",
    "\n",
    "**scan_time & time_increment:** 0.0: Tempo de varredura do sensor e tempo entre cada leitura. O valor 0.0 indica que o sensor está configurado para enviar as leituras o mais rápido possível.\n",
    "\n",
    "**range_min:** 0.119... [m]: Distância mínima que o sensor consegue detectar. O valor 0.119... equivale a 11.9 cm.\n",
    "\n",
    "**range_max:** 3.5 [m]: Distância máxima que o sensor consegue detectar. O valor 3.5 equivale a 3.5 m.\n",
    "\n",
    "**ranges:** [inf, inf, inf, ...]: Vetor com as leituras do sensor. O tamanho do vetor é igual a angle_max/angle_increment, ou seja, a lista de leituras é composta por 360 elementos que representam as leituras do sensor a cada 1 grau. O valor inf indica que o sensor não detectou nada naquela direção.\n",
    "\n",
    "**intensities:** [...]: Vetor com as intensidades das leituras do sensor. Nosso sensor não possui essa informação, portanto, pode desconsiderar esse campo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f96307",
   "metadata": {},
   "source": [
    "# Módulo 4 - Imagens e Matrizes \n",
    "\n",
    "## Leitura de Imagem e Webcam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4251ad",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "## Não esquecer de importar o opencv\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7fa449",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "## Ler imagem\n",
    "\n",
    "img = cv2.imread(\"path\",\"exemplo.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd08c405",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "## Mostrar a Imagem na Tela\n",
    "\n",
    "cv2.imshow(\"Imagem\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2952e5",
   "metadata": {},
   "source": [
    "Historicamente, a ordem dos sub-pixels das imagens usadas pelo OpenCV é invertida: em vez de `RGB` é `BGR`.\n",
    "\n",
    "Podemos fazer a conversão de `BGR` para `RGB` com a função `cv2.cvtColor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5e350",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "grid_rgb = cv2.cvtColor(grid, cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow(\"Imagem BGR\", grid_rgb)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b70240",
   "metadata": {},
   "source": [
    "Note que a célula superior esquerda agora é azul e a superior direita é vermelha. Isso acontece porque o **OpenCV SEMPRE entende que a imagem está no formato BGR, e não RGB.**\n",
    "\n",
    "Então quando fizemos a operação `cv2.cvtColor(grid, cv2.COLOR_BGR2RGB)`, não estamos **OBJETIVAMENTE** convertendo de BGR para RGB, mas apenas trocando a ordem dos canais de forma **SUBJETIVA**. Isso porque não existe um identificador para o formato RGB ou BGR, mas apenas uma **convenção** na hora de trabalhar com a imagem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a21e3",
   "metadata": {},
   "source": [
    "## Imagens como matrizes\n",
    "\n",
    "Se fizermos algo como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde7fd33",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "mini_grid = cv2.imread(\"img/img9x9.png\")\n",
    "\n",
    "print(mini_grid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15740249",
   "metadata": {},
   "source": [
    "Vamos obter \"(3, 3, 3)\" isso significa respectivamente 3 linhas, 3 colunas e 3 canais de cor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0592e7ae",
   "metadata": {},
   "source": [
    "## Transposta de uma matriz\n",
    "O código abaixo trará uma imagem com linhas e colunas transpostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d366e8b",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "trans = grid.transpose((1,0,2))\n",
    "\n",
    "cv2.imshow(\"Transposta\", trans)\n",
    "cv2.imshow(\"Original\", grid)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d27695",
   "metadata": {},
   "source": [
    "## Separando os canais da imagem\n",
    "O código abaixo separa os canais da imagem da arara:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b694a",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "arara_b, arara_g, arara_r = cv2.split(arara)\n",
    "print('arara.shape', arara.shape)\n",
    "print('arara_b.shape', arara_b.shape)\n",
    "print('arara_g.shape', arara_g.shape)\n",
    "print('arara_r.shape', arara_r.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0551563",
   "metadata": {},
   "source": [
    "Como as imagens são matrizes do numpy, podemos acessar os canais diretamente usando os índices.\n",
    "\n",
    "Por exemplo, para acessar o canal vermelho, usamos `img[:,:,2]`. O `:` significa \"todos os elementos da dimensão\". Ou seja, estamos acessando todos os elementos das dimensões 0 e 1, e o elemento 2 da dimensão 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d07c662",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "print('arara_b.shape', arara[:,:,0].shape)\n",
    "print('arara_g.shape', arara[:,:,1].shape)\n",
    "print('arara_r.shape', arara[:,:,2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ea9826",
   "metadata": {},
   "source": [
    "**Quando separamos os canais de cores de uma imagem, a interpretação é a seguinte:**\n",
    "\n",
    "**Nos canais separados, onde esta mais branco é onde tem mais da cor daquele canal. Se no canal vermelho por exemplo, tiver uma área muito branca, significa que na imagem original aquela área tem muita cor vermelha ou outras cores bem proximas do vermelho.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a64d95",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "## Voltando a imagem normal \n",
    "\n",
    "arara_rgb_original = cv2.merge([arara_b, arara_g, arara_r])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363c2e65",
   "metadata": {},
   "source": [
    "## Usando a Webcam\n",
    "### Foto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b57f11a",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(0)\n",
    "import time as t\n",
    "t.sleep(5) # Espera a webcam ficar pronta\n",
    "val, image = webcam.read()\n",
    "print(f'val = {val}')\n",
    "print(f'image.shape = {image.shape}')\n",
    "webcam.release() # fecha a webcam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abddd3b",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46271932",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"cam\")\n",
    "cv2.namedWindow(\"cam2\")\n",
    "while(True):\n",
    "    val, image = webcam.read()\n",
    "    if val:\n",
    "        ttt = image[:,:,0] #[linha, coluna, canal de cor] --> Colocamos zero ent é Blue no BGR\n",
    "        cv2.imshow(\"cam2\", ttt)\n",
    "        cv2.imshow(\"cam\", image)\n",
    "    if cv2.waitKey(1) == 27: # Aguarda 1 ms pela tecla 'ESC'\n",
    "        break\n",
    "            \n",
    "cv2.destroyAllWindows()\n",
    "webcam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fe7aa8",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "## Fazendo mostrar o vídeo da webcam diretamente com as cores invertidas\n",
    "webcam = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"cam\")\n",
    "\n",
    "while(True):\n",
    "    val, image = webcam.read()\n",
    "    webcam_b, webcam_g, webcam_r = cv2.split(image)\n",
    "    webcam_merge = cv2.merge([webcam_r, webcam_g, webcam_b])\n",
    "    if val:\n",
    "        cv2.imshow(\"cam\", webcam_merge)\n",
    "    if cv2.waitKey(1) == 27: # Aguarda 1 ms pela tecla 'ESC'\n",
    "        break\n",
    "            \n",
    "cv2.destroyAllWindows()\n",
    "webcam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57c30ce",
   "metadata": {},
   "source": [
    "## Corte e Criação de Imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b52ca",
   "metadata": {},
   "source": [
    "### Convertendo uma imagem para níveis de cinza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c40b9f5",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "entrada = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdccff1",
   "metadata": {},
   "source": [
    "### Copiando imagens \n",
    "Podemos usar a função `copy()` isso garantirá que a imagem de saída tenha o mesmo tamanho da imagem de entrada e **que a imagem de entrada não seja alterada**.\n",
    "EX: ***saida = entrada.copy( )***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1171c4e1",
   "metadata": {},
   "source": [
    "### Cortando uma imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc776d",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "horizontal = entrada.copy()\n",
    "vertical = entrada.copy()\n",
    "\n",
    "height, width = entrada.shape\n",
    "\n",
    "# Corte Horizontal\n",
    "horizontal[:int(height/2), :] = 0 #seleciona todas as linhas até a metade da altura da imagem (int(width/2)), \n",
    "#e todas as colunas (o : significa \"todas as colunas\")\n",
    "\n",
    "# Corte Vertical\n",
    "vertical[:, int(width/2):] = 0 #seleciona todas as linhas da imagem e as colunas da metade até o final\n",
    "#(ou seja, parte direita da imagem)\n",
    "\n",
    "cv2.imshow(\"Entrada\", entrada)\n",
    "cv2.imshow(\"Horizontal\", horizontal)\n",
    "cv2.imshow(\"Vertical\", vertical)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc85aa6",
   "metadata": {},
   "source": [
    "### Criando uma imagem vazia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a119cb",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "img_vazia = np.zeros((imagem, np.uint8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8856c7ef",
   "metadata": {},
   "source": [
    "### Adicionando texto em uma imagem\n",
    "\n",
    "- Img: A imagem onde será escrito o texto.\n",
    "- texto: O texto a ser escrito.\n",
    "- Posição: A posição do texto.\n",
    "- cv2.FONT_HERSHEY_SIMPLEX: O tipo de fonte do texto, neste caso, a fonte é a cv2.FONT_HERSHEY_SIMPLEX.\n",
    "- 1: O tamanho do texto.\n",
    "- (255, 0, 0): A cor do texto, neste caso, a cor é azul.\n",
    "- 2: A espessura do texto.\n",
    "- cv2.LINE_AA: O tipo de linha do texto, neste caso, a linha é cv2.LINE_AA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ffc4b",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "cv2.putText(img, texto, (Posição) cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34610785",
   "metadata": {},
   "source": [
    "## ROI e Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099c19df",
   "metadata": {},
   "source": [
    "* Determinação de uma região retangular na imagem que se quer processar, de fora que ela possua as características de interesse.\n",
    "\n",
    "* Uma ROI define uma sub-imagem da imagem original, com menos linhas e/cou colunas\n",
    "\n",
    "\n",
    "Para a definição de uma ROI, é necessário estabelecer:\n",
    "\n",
    "* A linha inicial (`miny`)\n",
    "\n",
    "* A coluna inicial (`minx`)\n",
    "\n",
    "* A linha final (`maxy`)\n",
    "\n",
    "* A coluna final (`maxx`)\n",
    "\n",
    "\n",
    "A imagem do OpenCV em Python é armazenada dentro de uma estrutura tipo `array` bidimensional (tons de cinza) ou tridimensional (colorida)do pacote `numpy`, que permite a definição de ROIs através do fatiamento (*slicing*) dos eixos do `array`. Dessa forma, recuperamos uma ROI através do acesso por chaves:\n",
    "\n",
    "`roi = imagem[minyy:maxy, minx:maxx]`\n",
    "\n",
    "**Atenção:** os limites `maxy` e `maxx`para a linha e coluna respectivamente não estão inclusos na ROI.\n",
    "Além disso, o acesso às linhas e colunas da nova imagem devem obedecer novos índices, começando pela linha 0 e coluna 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8de6b",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "minx, miny = 50, 50\n",
    "maxx, maxy = 250, 250\n",
    "\n",
    "yellow_bgr = (0,255,255)\n",
    "arara_corte = cv2.rectangle(arara, (minx, miny), (maxx, maxy), yellow_bgr, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd38fc",
   "metadata": {},
   "source": [
    "O comando `cv2.rectangle` desenha um retângulo na imagem. Para isso, temos os seguintes parâmetros:\n",
    "\n",
    "* A imagem que será desenhada\n",
    "\n",
    "* As coordenadas do canto **superior esquerdo**\n",
    "\n",
    "* As coordenadas do canto **inferior direito**\n",
    "\n",
    "* A cor do retângulo\n",
    "\n",
    "* A espessura da linha, mude para `-1` para preencher o retângulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ee787",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "## Se fizermos o imshow com a arara_corte, teremos a mesma imagem da arara porém com um retangulo amarelo desenhado\n",
    "# na região delimitada\n",
    "\n",
    "#Para efetivamente cortar a imagem na região delimitada precisamos fazer o seguinte\n",
    "recorte = arara_corte[miny: maxy,minx: maxx]\n",
    "\n",
    "#e dps o imshow de recorte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb33ddb",
   "metadata": {},
   "source": [
    "### Da pra pegar média, min, max dos pixels só fazendo o seguinte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07d0a95",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "minimo = np.min(rintin_gray)\n",
    "maximo = np.max(rintin_gray)\n",
    "media = np.mean(rintin_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf2d278",
   "metadata": {},
   "source": [
    "### Operações Condicionais\n",
    "\n",
    "Por exemplo, podemos fazer uma operação que retorna torna todos os pixels maiores que a média sejam convertivos para 255 e os menores que a média para 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba15283",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Fica um preto ou branco bem fajuto parecendo aqueles desenhos do nordeste (xilogravura)\n",
    "\n",
    "\n",
    "codicionado = rintin_gray.copy()\n",
    "codicionado[codicionado < media] = 0\n",
    "codicionado[codicionado >= media] = 255\n",
    "\n",
    "cv2.imshow(\"Rintin\", rintin_gray)\n",
    "cv2.imshow(\"Condicionado\", codicionado)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60b9daa",
   "metadata": {},
   "source": [
    "### Área\n",
    "Após a condição, a imagem resultante é binária, ou seja, só tem dois valores: 0 e 255. Podemos usar isso para calcular a área da parte branca da imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b6fec",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "## Podemos fazer de duas formas, a primeira é:\n",
    "area = np.count_nonzero(codicionado)\n",
    "\n",
    "# A segunda é:\n",
    "area = np.sum(codicionado/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1aad32",
   "metadata": {},
   "source": [
    "# Segmentação de Imagens\n",
    "\n",
    "### Máscaras\n",
    "Uma máscara é uma imagem binária que é usada para selecionar uma parte da imagem original. Podemos criar uma máscara com a função cv2.inRange que define os limites para seleção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876a6d9c",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "## Separando os canais pra analisar \n",
    "cores_r = cores_rgb[:,:,0]\n",
    "cores_g = cores_rgb[:,:,1]\n",
    "cores_b = cores_rgb[:,:,2]\n",
    "\n",
    "# Lendo a imagem\n",
    "img = cv2.imread(\"path/exemplo.png\")\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Definindo os limites da máscara\n",
    "inferior = (0,80,0) #RGB\n",
    "superior = (20,255,50) #RGB\n",
    "\n",
    "# Criando a máscara\n",
    "mask = cv2.inRange(img_rgb, inferior, superior)\n",
    "\n",
    "\n",
    "##### É interessante filtrar as cores em canais diferentes pra poder escolher os valores corretos de inferior e superior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb131f5",
   "metadata": {},
   "source": [
    "### Calcular a área da máscara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d769fd5",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "area = cv2.countNonZero(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4044355",
   "metadata": {},
   "source": [
    "### Máscara de Imagens em Preto e Branco\n",
    "A função cv2.inRange realiza a operação de limiarização.\n",
    "\n",
    "Para o caso de imagens preto e branco, a função cv2.inRange recebe como parâmetros a imagem de entrada, o valor mínimo e o valor máximo do intervalo de valores que serão considerados para a limiarização.\n",
    "\n",
    "O resultado da função é uma imagem binária, onde os pixels que estão dentro do intervalo são brancos e os pixels que estão fora do intervalo são pretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d7b3b",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Lendo a imagem\n",
    "img_gray = cv2.imread(\"path/exemplo.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Criando a máscara \n",
    "mask = cv2.inRange(img, 0, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e52606",
   "metadata": {},
   "source": [
    "## HSV - Melhor jeito para trabalhar com filtros em imagens coloridas\n",
    "![hsv](HSV_cylinder.jpg)\n",
    "![hsv2](hsv.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12b4b9",
   "metadata": {},
   "source": [
    "## `No circulo acima, lembre-se de dividir o valor H por 2 no momento que estiver determinando seu filtro na OpenCV. S e V são valores percentuais de 0% até 100%, lembre-se de converter para valores de 0 - 255 no momento que estiver determinando seu filtro na OpenCV.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0aa356",
   "metadata": {},
   "source": [
    "## Criando somente a máscara de imagens coloridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f7227b",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Lendo a imagem\n",
    "img = cv2.imread(\"path/exemplo.png\")\n",
    "\n",
    "# Convertendo a imagem para o espaço de cores HSV\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Definindo os limites da máscara\n",
    "inferior = (0, 50, 50)\n",
    "superior = (10, 255, 255)\n",
    "\n",
    "# Criando a máscara\n",
    "mask = cv2.inRange(img_hsv, inferior, superior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6669a94",
   "metadata": {},
   "source": [
    "## Criando a mascara e ja aplicando o filtro que só mostra ela ja colorida (exemplo com vermelho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af2c693",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Lendo a imagem\n",
    "img = cv2.imread(\"path/exemplo.png\")\n",
    "\n",
    "img_color = cv2.resize(img_color, (0, 0), fx=0.5, fy=0.5) # reduz a imagem para metade do tamanho\n",
    "\n",
    "# Convertendo a imagem para o espaço de cores HSV\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "low = np.array([0, 50, 50])\n",
    "high = np.array([10, 255, 255])\n",
    "mask = cv2.inRange(img_hsv, low, high)\n",
    "\n",
    "selecao = cv2.bitwise_and(img_color, img_color, mask=mask)\n",
    "\n",
    "cv2.imshow(\"mask\", mask)\n",
    "cv2.imshow(\"selecao\", selecao)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c28f512",
   "metadata": {},
   "source": [
    "No exemplo acima, utilizamos novamente a função `cv2.inRange()` para criar uma máscara que seleciona apenas os pixels que pertencem a caixa vermelha.\n",
    "\n",
    "Depois, utilizando a operação `AND` da OpenCV, aplicamos a máscara na imagem original, para que apenas os pixels que pertencem à caixa vermelha sejam exibidos.\n",
    "\n",
    "Acima usamos uma máscara usando a função `cv2.inRange()` para segmentar a imagem `img_color` com base em intervalos de cor definidos pelos arrays `low` e `high`. Então, `cv2.bitwise_and()` é usada para manter apenas os pixels na imagem `img_color` que correspondem à máscara `mask`. Isso cria uma imagem chamada `selecao`, que contém apenas os pixels da imagem original que estão dentro dos intervalos de cor especificados pela máscara.\n",
    "\n",
    "Para o valor de H, pelo círculo HSV acima, podemos ver que o vermelho está entre 0 e 30, e entre 150 e 180, para essa imagem, escolhemos o intervalo entre 0 e 10.\n",
    "\n",
    "No caso dos valores de `Saturation` e `Value``, escolhemos o intervalo entre 50 e 255, pois queremos que a cor seja bem saturada e brilhante, como podemos observar no retângulo HSV acima."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3887ae",
   "metadata": {},
   "source": [
    "### Operação OR (normalmente usado para combinar duas máscaras)\n",
    "Abaixo, temos o código para realizar a segmentação da cor vermelha, neste código, combinamos as duas máscaras resultantes utilizando o operador lógico OR do OpenCV, que retorna branco se pelo menos um dos pixels for branco. A função cv2.bitwise_or recebe os seguintes parâmetros:\n",
    "\n",
    "- cv2.bitwise_or(src1, src2, **mask)\n",
    "- src1: primeira imagem, ou máscara, de entrada ou matriz real.\n",
    "- src2: segunda imagem, ou máscara, de entrada ou matriz real.\n",
    "- mask (opcional): máscara de entrada de 8 bits. A operação será realizada apenas nos elementos especificados pela máscara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7083da",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Lendo a imagem\n",
    "img = cv2.imread(\"path/exemplo.png\")\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Definindo os limites da máscara 1\n",
    "cor_menor1 = np.array([172, 50, 50])\n",
    "cor_maior1 = np.array([180, 255, 255])\n",
    "\n",
    "# Criando a máscara 1\n",
    "mask_1 = cv2.inRange(img_hsv, cor_menor1, cor_maior1)\n",
    "\n",
    "# Definindo os limites da máscara 2\n",
    "cor_menor2 = np.array([0, 50, 50])  #Quando for definir o H, (primeira coluna) posso colocar tipo 280//2 pra ficar mais facil\n",
    "cor_maior2 = np.array([8, 255, 255])\n",
    "\n",
    "# Criando a máscara 2\n",
    "mask_2 = cv2.inRange(img_hsv, cor_menor2, cor_maior2)\n",
    "\n",
    "# Combinando as máscaras\n",
    "mask_combinada = cv2.bitwise_or(mask_1, mask_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3f2b1d",
   "metadata": {},
   "source": [
    "# Módulo 5 - Identificação e Visão na ROS 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd2b872",
   "metadata": {},
   "source": [
    "## Gravando mensagens - Rosbag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086a3125",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dda4c9a",
   "metadata": {},
   "source": [
    "## Refinamento de Máscaras de Segmentação\n",
    "### Operações Morfológicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e07b7fe",
   "metadata": {},
   "source": [
    "Nos exemplos anteriores, notamos frequentemente que as máscaras geradas apresentam buracos e/ou ilhas. Para esclarecer:\n",
    "- **Buracos** são pequenos segmentos de pixels pretos dentro de regiões de pixels brancos\n",
    "- **Ilhas** são pequenos segmentos de pixels brancos dentro de regiões de pixels pretos.\n",
    "\n",
    "As operaçõs morfologicas se baseiam em duas operações em um kernel (janela quadrada que definimos, ou seja, campo de análise):\n",
    "- **Erosão** remove pequenas manchas brancas (ilhas) e estreita regiões brancas maiores.\n",
    "- **Dilatação** Oposto da erosão, portanto aumenta regiões brancas preenchendo buracos e expandindo áreas brancas menores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7008d",
   "metadata": {},
   "source": [
    "Nele, vamos utilizar as seguintes funções do OpenCV:\n",
    "\n",
    "* `cv2.getStructuringElement`: Cria um elemento estruturante (kernel) para ser utilizado nas operações morfológicas. Recebe os seguintes parâmetros:\n",
    "    * `shape`: Forma do kernel. Pode ser `cv2.MORPH_RECT` (retangular), `cv2.MORPH_ELLIPSE` (elíptico) ou `cv2.MORPH_CROSS` (cruz).\n",
    "    * `ksize`: Tamanho do kernel. Deve ser uma tupla com dois valores inteiros positivos.\n",
    "\n",
    "* `cv2.morphologyEx`: Aplica uma operação morfológica em uma imagem. Recebe os seguintes parâmetros:\n",
    "    * `src`: Imagem de entrada.\n",
    "    * `op`: Tipo de operação morfológica. Pode ser `cv2.MORPH_OPEN` (abertura), `cv2.MORPH_CLOSE` (fechamento), `cv2.MORPH_ERODE` (erosão) ou `cv2.MORPH_DILATE` (dilatação).\n",
    "    * `kernel`: Elemento estruturante (kernel) a ser utilizado na operação morfológica.\n",
    "\n",
    "    EXEMPLO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2102a828",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Vamos considerar que ja temos uma mask feita anteriormente para a cor violeta\n",
    "\n",
    "# Definição do kernel, é basicamente qual a distancia que queremos que ele olhe em cada pixel.\n",
    "# Se deixarmos maior, tipo (10, 10) no erode ele vai estreitar muito o branco e realçar mais os pontos pretos\n",
    "# Já no dilatate vai deixar as linhas brancas mais grossas.\n",
    "# Tudo isso por conta do tamanho do kernel que é a \"raio\" de análise em cada pixel\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "\n",
    "# Operações Morfológicas\n",
    "mask_erode = cv2.morphologyEx(mask_violeta, cv2.MORPH_ERODE, kernel)\n",
    "mask_dilate = cv2.morphologyEx(mask_violeta, cv2.MORPH_DILATE, kernel)\n",
    "\n",
    "cv2.imshow(\"image\", img)\n",
    "cv2.imshow(\"Erosao\", mask_erode)\n",
    "cv2.imshow(\"Dilatacao\", mask_dilate)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721304cb",
   "metadata": {},
   "source": [
    "### Abertura \n",
    "\n",
    "Ao invés de fazer uma operação de cada vez, podemos usar a operação de abertura.\n",
    "\n",
    "Nela são realizadas as operações de `erosão` e depois de `dilatação`. A ideia é **eliminar pequenas ilhas**, que seriam eliminadas na erosão, e depois **restaurar as dimensões** dos agrupamentos brancos restantes. Vamos ver um exemplo de uso da abertura na máscara em que identificamos os trechos de cor violeta   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd27beb4",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Cria uma janela 3x3 como elemento estruturante este elemente tem a forma de um quadrado\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "# Quanto maior o numero do kernel, parece que fica mais grosseiro\n",
    "\n",
    "# realiza a abertura\n",
    "mask_open = cv2.morphologyEx(mask_violeta, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "cv2.imshow(\"image\", img)\n",
    "cv2.imshow(\"Original\", mask_violeta)\n",
    "cv2.imshow(\"Abertura\", mask_open)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1596d2d0",
   "metadata": {},
   "source": [
    "### Fechamento\n",
    "\n",
    "Já no fechamento a operação é inversa, primeiro `dilatação` e depois `erosão`. A ideia é **fechar pequenos buracos**, que seriam eliminadas na dilatação, e depois **restaurar as dimensões** dos agrupamentos restantes. Vamos usar a mesma imagem como exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ac06f",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Cria uma janela 3x3 como elemento estruturante este elemente tem a forma de um quadrado\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "\n",
    "# realiza a abertura\n",
    "mask_close = cv2.morphologyEx(mask_violeta, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "cv2.imshow(\"image\", img)\n",
    "cv2.imshow(\"Original\", mask_violeta)\n",
    "cv2.imshow(\"Fechamento\", mask_close)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb5b28c",
   "metadata": {},
   "source": [
    "### Usando os dois de uma vez só (abertura e fechamento)\n",
    "\n",
    "Para isso será usado um elemento estruturante no formato de uma elipse 5x5. Porque o objeto que queremos segmentar é mais proximo de uma elipse do que de um quadrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483fd46a",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Cria uma janela 3x3 como elemento estruturante este elemente tem a forma de um quadrado\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "\n",
    "# realiza a abertura\n",
    "mask = cv2.morphologyEx(mask_violeta, cv2.MORPH_OPEN, kernel)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "cv2.imshow(\"image\", img)\n",
    "cv2.imshow(\"Original\", mask_violeta)\n",
    "cv2.imshow(\"Resultado\", mask)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4371399",
   "metadata": {},
   "source": [
    "**Note que a abertura removeu as ilhas e o fechamento removeu os buracos, gerando uma máscara mais refinada.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bb7730",
   "metadata": {},
   "source": [
    "## Identificação de objetos\n",
    "\n",
    "### Contornos\n",
    "\n",
    "Os contornos podem ser encontrados em imagens binárias com `cv2.findContours`. Esses contornos podem ser usados para identificar e delimitar objetos. Contornos são úteis para encontrar a área, o centro de massa e a caixa delimitadora de um objeto. A função `cv2.findContours` recebe como parâmetros a **imagem binária de entrada**, o modo de organização dos contornos e o método de aproximação dos contornos\n",
    "\n",
    "```\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "```\n",
    "\n",
    "onde:\n",
    "* `mask` é a imagem com a máscara binária de entrada.  \n",
    "\n",
    "* `cv2.RETR_CCOMP` indica que queremos organizar os contornos em componentes conexos e buracos dentro deles - veja mais detalhes em [Contours Hierarchy](https://docs.opencv.org/4.x/d9/d8b/tutorial_py_contours_hierarchy.html). Organiza os contornos em duas hierarquias: contornos externos e internos.\n",
    "* `cv2.CHAIN_APPROX_NONE` indica que queremos armazenar todos os pontos do contorno.\n",
    "* `contours` é uma lista de contornos. Cada contorno é uma lista de pontos (x, y) que formam o polígono que delimita o contorno.\n",
    "* `hierarchy` é uma lista indicando a organização dos contornos em termos dos componentes e de seus buracos.\n",
    "\n",
    "\n",
    "### Dica:\n",
    "Quando queremos pegar o contorno de alguma coisa retangular uma boa ideia é usar o  `CHAIN_APPROX_SIMPLE` como um dos argumentos do `findContours` pois ele omprime os segmentos de linha horizontais, verticais e diagonais, deixando apenas seus pontos finais. Por exemplo, um retângulo contornado será armazenado com apenas quatro pontos.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Como pegar o contorno externo:\n",
    "`cv2.RETR_EXTERNAL`: Este modo retorna apenas os contornos externos, ignorando quaisquer contornos aninhados dentro de outros contornos. \n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "Normalmente, junto com a função de achar os contornos, ja usamos a função de `desenhar os contornos`.\n",
    "\n",
    "\n",
    "```\n",
    "cv2.drawContours(img, contours, indice, cor)\n",
    "```\n",
    "\n",
    "* `img` é a imagem colorida ou tons de cinza onde serão desenhados os contornos.  \n",
    "\n",
    "* `contours` é a lista de contornos obtida com `cv2.findContours()`, ou seja, recebe uma lista de lista. Então assumindo que `contours[i]` seja um contorno, a função esperaria uma sintaxe como `cv2.drawContours(img, [contours[i]], indice, cor)`.\n",
    "* `indice` é o índice do contorno dentro da lista a ser desenhado; se `-1` desenha todos os contornos\n",
    "* `cor` é a cor do pixel a ser usada para desenhar o contorno, por exemplo, `(255, 0, 0)` para azul. Se for `-1`, o contorno é **preenchido** com a cor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa5cbac",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "print(f'Numero de Contornos Encontrados: {len(contornos)}')\n",
    "\n",
    "contornos_img = img.copy()\n",
    "cv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 3)\n",
    "\n",
    "cv2.imshow(\"contornos_img\", contornos_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e45a88",
   "metadata": {},
   "source": [
    "Para o exemplo acima, ficamos com a seguinte imagem:\n",
    "<br>\n",
    "<br>\n",
    "![imagem](contornos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be5463c",
   "metadata": {},
   "source": [
    "## Exemplo pegando os contornos externos das latinhas somente\n",
    "![externo](externo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddbebba",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Carregar a imagem\n",
    "img = cv2.imread(\"img/coke-cans.jpg\")\n",
    "\n",
    "# Converter a imagem para o espaço de cores HSV\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "# Definir a faixa de cor para o branco (fundo)\n",
    "lower_white = np.array([0, 0, 200])\n",
    "upper_white = np.array([180, 30, 255])\n",
    "\n",
    "# Criar uma máscara para os pixels brancos\n",
    "mask_white = cv2.inRange(hsv, lower_white, upper_white)\n",
    "\n",
    "# Inverter a máscara (para manter o que não é branco)\n",
    "mask = cv2.bitwise_not(mask_white)\n",
    "\n",
    "# Aplicar a máscara na imagem original para manter apenas as latas\n",
    "result = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "# Converter a imagem resultante para escala de cinza para poder usar \"cv2.findContours\"\n",
    "gray_result = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detectar contornos externos\n",
    "# As vezes ao inves de colocar o\"gray_result\" seja melhor colocar \"mask\" testar na hora\n",
    "contours, hierarchy = cv2.findContours(gray_result, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Desenhar os contornos na imagem original\n",
    "result_with_contours = img.copy()\n",
    "cv2.drawContours(result_with_contours, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Exibir a imagem com os contornos\n",
    "cv2.imshow(\"Contornos das latas\", result_with_contours)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea1e0f2",
   "metadata": {},
   "source": [
    "## Medidas dos contornos\n",
    "\n",
    "A partir dos contornos, podemos tirar uma série de medidas como:\n",
    "- **Área:** número de pixels pertencentes ao contorno, calculada com `cv2.contourArea(contour)`\n",
    "- **Centro de massa:** linha e coluna do centro de massa do contorno\n",
    "- **Caixa delimitadora:** menor retângulo que contém o contorno, calculada com `cv2.boundingRect(contour)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1ba2f",
   "metadata": {},
   "source": [
    "### Calculando o maior contorno e sem seguida mostrando somente ele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e1bd7",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Lendo a imagem\n",
    "img = cv2.imread(\"path/exemplo.png\")\n",
    "\n",
    "# Encontrando os contornos\n",
    "contours, hierarchy = cv2.findContours(mask_combinada, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Encontrando o maior contorno\n",
    "maior_contorno = max(contours, key=cv2.contourArea)\n",
    "\n",
    "# Desenhando o maior contorno\n",
    "img_maior_contorno = img.copy()\n",
    "cv2.drawContours(img_maior_contorno, [maior_contorno], -1, [255,0,0], 3)\n",
    "\n",
    "#mostrando a imagem\n",
    "cv2.imshow(\"maior contorno\", img_maior_contorno)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927723a5",
   "metadata": {},
   "source": [
    "### Centro de massa do contono\n",
    "\n",
    "O centro de massa de um contorno é calculado através da função `cv2.moments(contour)`, que retorna um dicionário com as seguintes chaves:\n",
    "* `m00`: área do contorno\n",
    "* `m10`: soma das coordenadas x dos pixels do contorno\n",
    "* `m01`: soma das coordenadas y dos pixels do contorno\n",
    "\n",
    "Essas chaves são usadas para calcular o centro de massa do contorno, que é dado por:\n",
    "```\n",
    "cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "cY = int(M[\"m01\"] / M[\"m00\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032c06b6",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Lendo a imagem\n",
    "img = cv2.imread(\"path/exemplo.png\")\n",
    "\n",
    "# Imagem onde os contornos serão desenhados\n",
    "contornos_img = img.copy()\n",
    "\n",
    "# Encontrando os contornos\n",
    "contours, hierarchy = cv2.findContours(mask_combinada, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Encontrando o maior contorno\n",
    "maior_contorno = max(contours, key=cv2.contourArea)\n",
    "\n",
    "# Funçaõ para desenhar um crosshair\n",
    "def crosshair(img, point, size, color):\n",
    "    \"\"\" Desenha um crosshair centrado no point. ) point deve ser uma tupla (x,y). O color é uma tupla R,G,B uint8 \"\"\"\n",
    "    x,y = point\n",
    "    cv2.line(img,(x - size,y),(x + size,y),color,5)\n",
    "    cv2.line(img,(x,y - size),(x, y + size),color,5)\n",
    "\n",
    "    return img\n",
    "\n",
    "# Retorna uma tupla (cx, cy) que desenha o centro do contorno\n",
    "M = cv2.moments(maior)\n",
    "\n",
    "# Usando a expressão do centróide definida em: https://en.wikipedia.org/wiki/Image_moment\n",
    "cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "#Desenha o centro do contorno com um crosshair\n",
    "contornos_img = crosshair(contornos_img, (cX,cY), 10, (255,0,0))\n",
    "\n",
    "cv2.imshow(\"contornos_img\", contornos_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f361ea5",
   "metadata": {},
   "source": [
    "## Caixa Delimitadora\n",
    "\n",
    "Uma caixa delimitadora é um retângulo que delimita as coordenadas de um objeto. A caixa delimitadora é definida pelas coordenadas de seu canto superior esquerdo e sua largura e altura.\n",
    "\n",
    "A função `cv2.boundingRect(contour)` retorna as coordenadas do canto superior esquerdo e a largura e altura da caixa delimitadora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca87cf",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Lendo a imagem\n",
    "img = cv2.imread(\"path/exemplo.png\")\n",
    "\n",
    "# Imagem onde a caixa delimitadora será desenhada\n",
    "caixa_img = img.copy()\n",
    "\n",
    "# Encontrando os contornos\n",
    "contours, hierarchy = cv2.findContours(mask_combinada, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Encontrando o maior contorno\n",
    "maior_contorno = max(contours, key=cv2.contourArea)\n",
    "\n",
    "# Encontrando a caixa delimitadora\n",
    "x, y, w, h = cv2.boundingRect(maior_contorno)\n",
    "\n",
    "# Desenhando a caixa delimitadora\n",
    "cv2.rectangle(caixa_img, (x, y), (x + w, y + h), (0, 255, 0), 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9f2318",
   "metadata": {},
   "source": [
    "![caixa](delimitadora.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e8b38e",
   "metadata": {},
   "source": [
    "## Exemplo usando várias coisas mostradas acima:\n",
    "**Exercício 3:** Abra a imagem `pingpong.jpg` e desenhe o centro de massa e a caixa delimitadora da bolinha laranja. Imprima também a sua área na tela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9045bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lendo a imagem\n",
    "img = cv2.imread(\"img/pingpong.jpg\")\n",
    "#Transformando em HSV\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "#definindo parametros da mascara\n",
    "lower = np.array([26//2, 0, 0])\n",
    "upper = np.array([38//2, 255, 255])\n",
    "\n",
    "#Aplicando a mascara\n",
    "mask = cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "#Fazendo uma abertura e um fechamento na mascara para melhorar \n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "#Juntando a mascara com a imagem original\n",
    "result = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "#Transformando em escala de cinza pra poder usar o \"find Contours\"\n",
    "gray_result = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# Encontrando os contornos na imagem em cinza, usando external pra pegar a bola inteira mais facil\n",
    "contours, hierarchy = cv2.findContours(gray_result, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "#Copiando a imagem original pra não alterar ela e desenhando os contornos\n",
    "result_with_contours = img.copy()\n",
    "cv2.drawContours(result_with_contours, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Função para desenhar um crosshair\n",
    "def crosshair(img, point, size, color):\n",
    "    \"\"\" Desenha um crosshair centrado no point. ) point deve ser uma tupla (x,y). O color é uma tupla R,G,B uint8 \"\"\"\n",
    "    x,y = point\n",
    "    cv2.line(img,(x - size,y),(x + size,y),color,5)\n",
    "    cv2.line(img,(x,y - size),(x, y + size),color,5)\n",
    "\n",
    "    return img\n",
    "\n",
    "#Pegando o maior (e unico nesse caso) contorno só pra dar uma variavel a ele\n",
    "maior_contorno = max(contours, key=cv2.contourArea)\n",
    "\n",
    "# Retorna uma tupla (cx, cy) que desenha o centro do contorno\n",
    "M = cv2.moments(maior_contorno)\n",
    "\n",
    "# Usando a expressão do centróide definida em: https://en.wikipedia.org/wiki/Image_moment\n",
    "cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "#Desenha o centro do contorno com um crosshair\n",
    "result_with_contours = crosshair(result_with_contours, (cX,cY), 10, (255,0,0))\n",
    "\n",
    "# Encontrando a caixa delimitadora\n",
    "x, y, w, h = cv2.boundingRect(maior_contorno)\n",
    "\n",
    "# Desenhando a caixa delimitadora\n",
    "cv2.rectangle(result_with_contours, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "#Encontrando a área da bolinha\n",
    "area = np.count_nonzero(mask)\n",
    "print(area)\n",
    "\n",
    "cv2.imshow(\"mask\", mask)\n",
    "cv2.imshow(\"selecao\", result_with_contours)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1329ef",
   "metadata": {},
   "source": [
    "![ex3](ex3_area.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c7a3e9",
   "metadata": {},
   "source": [
    "## Processando imagens na ROS 2\n",
    "\n",
    "### Código que se inscreve no tópico de imagem da câmera do robô (image_subscriber.py)\n",
    "OBS: Coloquei o arquivo tbm em colcol_ws/src/codigos_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d934ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from sensor_msgs.msg import Image, CompressedImage\n",
    "from cv_bridge import CvBridge\n",
    "from rclpy.qos import ReliabilityPolicy, QoSProfile\n",
    "from std_msgs.msg import String\n",
    "import cv2\n",
    "\n",
    "class ImageNode(Node): # Mude o nome da classe\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__('image_tool_node')\n",
    "        self.runnable = True\n",
    "\n",
    "        # Subscribers\n",
    "        ## Coloque aqui os subscribers\n",
    "        self.bridge = CvBridge()\n",
    "        self.image_sub = self.create_subscription(\n",
    "            Image, # or CompressedImage\n",
    "            '/camera/image_raw', # or '/camera/image_raw/compressed'\n",
    "            self.image_callback,\n",
    "            QoSProfile(depth=10, reliability=ReliabilityPolicy.BEST_EFFORT))\n",
    "        \n",
    "        self.flag_sub = self.create_subscription(\n",
    "            String,\n",
    "            '/vision/image_flag', # Mude o nome do tópico\n",
    "            self.flag_callback,\n",
    "            QoSProfile(depth=10, reliability=ReliabilityPolicy.BEST_EFFORT))\n",
    "\n",
    "        # Publishers\n",
    "        ## Coloque aqui os publishers\n",
    "\n",
    "    def flag_callback(self, msg):\n",
    "        self.runnable = bool(msg.data)\n",
    "    \n",
    "    #Aqui é onde a imagem é processada\n",
    "    def image_callback(self, msg):\n",
    "        if self.runnable:\n",
    "            cv_image = self.bridge.imgmsg_to_cv2(msg, \"bgr8\") # if Image\n",
    "            cv2.imshow('Image', cv_image)\n",
    "            cv2.waitKey(1)\n",
    "            # cv_image = self.bridge.compressed_imgmsg_to_cv2(msg, \"bgr8\") # if CompressedImage\n",
    "            \n",
    "            # Faça aqui o processamento da imagem\n",
    "            # ou chame uma classe ou função que faça isso\n",
    "        else:\n",
    "            print('Image processing is paused')\n",
    "\n",
    "    \n",
    "def main(args=None):\n",
    "    rclpy.init(args=args)\n",
    "    ros_node = ImageNode() # Mude o nome da classe\n",
    "\n",
    "    rclpy.spin(ros_node)\n",
    "\n",
    "    ros_node.destroy_node()\n",
    "    rclpy.shutdown()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d1e2c",
   "metadata": {},
   "source": [
    "## Processando Imagens na ROS 2\n",
    "\n",
    "Na pasta de arquivos base temos o arquivo `image_subscriber` que se inscreve no topico de imagem da cãmera do robô.\n",
    "Aqui está o código do arquivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01f70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from sensor_msgs.msg import Image, CompressedImage\n",
    "from cv_bridge import CvBridge\n",
    "from rclpy.qos import ReliabilityPolicy, QoSProfile\n",
    "from std_msgs.msg import String\n",
    "import cv2\n",
    "\n",
    "class ImageNode(Node): # Mude o nome da classe\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__('image_tool_node')\n",
    "        self.runnable = True\n",
    "\n",
    "        # Subscribers\n",
    "        ## Coloque aqui os subscribers\n",
    "        self.bridge = CvBridge()\n",
    "        self.image_sub = self.create_subscription(\n",
    "            Image, # or CompressedImage\n",
    "            '/camera/image_raw', # or '/camera/image_raw/compressed'\n",
    "            self.image_callback,\n",
    "            QoSProfile(depth=10, reliability=ReliabilityPolicy.BEST_EFFORT))\n",
    "        \n",
    "        self.flag_sub = self.create_subscription(\n",
    "            String,\n",
    "            '/vision/image_flag', # Mude o nome do tópico\n",
    "            self.flag_callback,\n",
    "            QoSProfile(depth=10, reliability=ReliabilityPolicy.BEST_EFFORT))\n",
    "\n",
    "        # Publishers\n",
    "        ## Coloque aqui os publishers\n",
    "\n",
    "    def flag_callback(self, msg):\n",
    "        self.runnable = bool(msg.data)\n",
    "\n",
    "    def image_callback(self, msg):\n",
    "        if self.runnable:\n",
    "            cv_image = self.bridge.imgmsg_to_cv2(msg, \"bgr8\") # if Image\n",
    "            cv2.imshow('Image', cv_image)\n",
    "            cv2.waitKey(1)\n",
    "            # cv_image = self.bridge.compressed_imgmsg_to_cv2(msg, \"bgr8\") # if CompressedImage\n",
    "            \n",
    "            # Faça aqui o processamento da imagem\n",
    "            # ou chame uma classe ou função que faça isso\n",
    "        else:\n",
    "            print('Image processing is paused')\n",
    "\n",
    "    \n",
    "def main(args=None):\n",
    "    rclpy.init(args=args)\n",
    "    ros_node = ImageNode() # Mude o nome da classe\n",
    "\n",
    "    rclpy.spin(ros_node)\n",
    "\n",
    "    ros_node.destroy_node()\n",
    "    rclpy.shutdown()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c3d20",
   "metadata": {},
   "source": [
    "No `image_callback` a imagem recebida é convertida para um objeto do tipo numpy.ndarray utilizando a função imgmsg_to_cv2 ou compressed_imgmsg_to_cv2 da biblioteca cv_bridge. No __init__ do código, definimos a variável self.bridge como CvBridge(), essa biblioteca é uma ponte (bridge) entre a biblioteca OpenCV e a ROS, que trabalham com formatos de imagem diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c308d1f6",
   "metadata": {},
   "source": [
    "Outro ponto importante é a variável self.runnable, obtida do tópico /vision/image_flag. Enquanto o valor dessa variável for True, o processamento da imagem é feito, então, um outro nó pode publicar nesse tópico para pausar ou retomar o processamento da imagem. Isso é útil para economizar recursos do robô quando o processamento da imagem não é necessário, será útil para quando estivermos processando imagens usando `Redes Neurais` ou `Aruco Markers`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4328446",
   "metadata": {},
   "source": [
    "Por ultimo, ainda no método image_callback, a variável cv_image contém a imagem recebida. Neste ponto, você pode fazer o processamento da imagem ou chamar uma função ou classe que faça isso para manter o código organizado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eb6b43",
   "metadata": {},
   "source": [
    "## Ferramentas de Visão - Image Tool\n",
    "\n",
    "**Como rodar o image_tool:** <br>\n",
    "<br>\n",
    "ros2 run image_tool start_image_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98855ba9",
   "metadata": {},
   "source": [
    "A ferramenta de imagem importa uma classe chamada ImageModule, do arquivo image_module.py, que faz o processamento da imagem recebida pela ROS. Por padrão, a classe apenas faz a filtragem de cor da imagem com os limites de cor definidos na GUI da ferramenta de imagem.\n",
    "\n",
    "Na função run da classe ImageModule você pode adicionar o processamento que desejar para a imagem, como por exemplo, a detecção de contornos e a identificação de objetos.\n",
    "\n",
    "Dessa forma você pode testar os limites e depois, você pode levar a classe ImageModule para o seu código e utilizá-la para processar as imagens recebidas pela ROS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d19751",
   "metadata": {},
   "source": [
    "## Exercício de Visão - Detecção de Bandeiras\n",
    "Essa questão consiste em identificar bandeiras de vários países em imagens. Um processo anterior já removeu o fundo, então só nos resta dizer qual é qual. Iremos analisar os seguintes países. Veja na pasta `img/q1` exemplos de todas essas bandeiras nas imagens de teste.\n",
    "\n",
    "1. Mônaco\n",
    "2. Peru\n",
    "3. Singapura\n",
    "4. Irlanda\n",
    "5. Itália\n",
    "\n",
    "Você deverá editar a classe `IdentificadorBandeiras` do arquivo [q1.py](/docs/modulos/05-visao-p2/atividades/util/q1.py) para realizar essa questão. Nesta classe, você deve implementar a função `run` para identificar as bandeiras. A função `run` recebe uma imagem e modifica a variável da classe `self.bandeiras` que é uma lista de tuplas no formato\n",
    "\n",
    "\n",
    "```\n",
    "(PAIS, (x1, y2), (x2, y2)`)\n",
    "```\n",
    "\n",
    "\n",
    "onde\n",
    "\n",
    "\n",
    "- `PAIS` é uma string com o nome do país tratado (em minúsculas e sem espaços). Se você não conseguiu identificar uma bandeira, pode retornar uma lista.\n",
    "- `(x1, y1)` é o ponto do topo esquerdo do retângulo em que a bandeira está inserida\n",
    "- `(x2, y2)` é o ponto baixo direito do retângulo em que a bandeira está inserida\n",
    "\n",
    "\n",
    "**A ordem dos elementos da lista não é importante, apenas seu conteúdo**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa8496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class IdentificadorBandeiras():\n",
    "    def __init__(self) -> None: #Esse '-> None' indica que a função nao retorna nenhum valor\n",
    "        self.bandeiras = []\n",
    "\n",
    "    def run(self,bgr):\n",
    "        '''\n",
    "        Essa função deverá identificar as bandeiras na imagem passada como argumento\n",
    "        e devolver uma lista de tuplas no formato\n",
    "\n",
    "        ('pais', (x1, y1), (x2, y2))\n",
    "        '''\n",
    "\n",
    "        return self.bandeiras\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    bgr = cv2.imread('teste1.png')\n",
    "    q1 = IdentificadorBandeiras()\n",
    "    items = q1.run(bgr)\n",
    "\n",
    "    for it in items:\n",
    "        print(it)\n",
    "        cv2.rectangle(bgr, it[1], it[2], (255, 0, 0), 5)\n",
    "    \n",
    "    cv2.imshow(\"Resultado\", bgr)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6af744b",
   "metadata": {},
   "source": [
    "### Fazendo a leitura das Imagens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73de7d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "for i in range(1,5):\n",
    "    img = cv2.imread(f'teste{i}.png')\n",
    "    cv2.imshow(f'teste{i}.png', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "img = cv2.imread('teste1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47549b4",
   "metadata": {},
   "source": [
    "### Detecção das Bandeiras\n",
    "\n",
    "Em todas as imagem, note que o fundo é sempre preto. Podemos usar isso para encontrar as bandeiras.\n",
    "\n",
    "Se criarmos uma máscara que ignore o fundo, podemos encontrar as bandeiras facilmente. Isso foi feito na função abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0678d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_contours(bgr):\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    mask = cv2.inRange(gray, 20, 255)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    rects = []\n",
    "    for contour in contours:\n",
    "        rect = cv2.boundingRect(contour)\n",
    "        rects.append(rect)\n",
    "    \n",
    "    return bgr, rects\n",
    "\n",
    "bgr, rects = get_all_contours(img)\n",
    "\n",
    "bgr_ = bgr.copy()\n",
    "for rect in rects:\n",
    "    x, y, w, h = rect\n",
    "    cv2.rectangle(bgr_, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('img', bgr_)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df05ddb",
   "metadata": {},
   "source": [
    "### Comparação de Cores\n",
    "Agora, vamos encontrar os limites de cada cor na imagem, usar a função `cv2.inRange`, e calcular a area de cada cor. A cor com maior área é a cor predominante na imagem.\n",
    "\n",
    "Isso foi feito na função abaixo:\n",
    "Basicamente foi feito o seguinte. Criou um dicionario para poder determinar os limites de cada cor em RGB, em seguida fez uma função com vários ifs para determinar qual bandeira era qual. Então se tivesse laranja era da irlanda. Se não for da irlanda, entra em um elif que verifica se tem verde, caso tenha é da italia pois a da irlanda ja foi verificada.\n",
    "Em seguida verifica das bandeiras que tem cor vermelha e branco. Se tiver mais branco do que vermelho é de Singapura, se tiver mais vermelho do que branco é do Peru. Caso não seja nenhuma dessas então é de monaco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d03ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    'orange': ((0, 100, 100), (20, 255, 255)),\n",
    "    'red': ((170, 100, 100), (180, 255, 255)),\n",
    "    'green': ((70, 100, 100), (80, 255, 255)),\n",
    "    'white': ((0, 0, 200), (180, 20, 255)),\n",
    "}\n",
    "\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "\n",
    "bandeiras = []\n",
    "\n",
    "def checar_bandeiras(hsv, rects):\n",
    "    for rect in rects:\n",
    "        x, y, w, h = rect\n",
    "        crop = hsv[y:y+h, x:x+w]\n",
    "        cv2.imshow('crop', cv2.cvtColor(crop, cv2.COLOR_HSV2BGR))\n",
    "\n",
    "        # Irlanda\n",
    "        if np.sum(cv2.inRange(crop, colors['orange'][0], colors['orange'][1])) > 0:\n",
    "            bandeiras.append(('irlanda', (x, y), (x+w, y+h)))\n",
    "        elif np.sum(cv2.inRange(crop, colors['green'][0], colors['green'][1])) > 0:\n",
    "            bandeiras.append(('italia', (x, y), (x+w, y+h)))\n",
    "        else:\n",
    "            mask_r = cv2.inRange(crop, colors['red'][0], colors['red'][1])\n",
    "            red = np.sum(mask_r) / 255\n",
    "            mask_w = cv2.inRange(crop, colors['white'][0], colors['white'][1])\n",
    "            white = np.sum(mask_w) / 255\n",
    "            if white > red:\n",
    "                bandeiras.append(('singapura', (x, y), (x+w, y+h)))\n",
    "            elif red > white:\n",
    "                bandeiras.append(('peru', (x, y), (x+w, y+h)))\n",
    "            else:\n",
    "                bandeiras.append(('monaco', (x, y), (x+w, y+h)))\n",
    "\n",
    "hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "checar_bandeiras(hsv, rects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b573a59f",
   "metadata": {},
   "source": [
    "Abaixo usamos a função `cv2.putText` para escrever o nome do país na imagem, que recebe os seguintes parâmetros:\n",
    "\n",
    "* A imagem onde será escrito o texto.\n",
    "* O texto a ser escrito.\n",
    "* A posição do texto.\n",
    "* A fonte do texto.\n",
    "* O tamanho do texto.\n",
    "* A cor do texto.\n",
    "* A espessura do texto.\n",
    "* O tipo de linha do texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae4ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bandeiras(bgr):\n",
    "    for bandeira in bandeiras:\n",
    "        cv2.rectangle(bgr, bandeira[1], bandeira[2], (255, 0, 0), 5)\n",
    "        cv2.putText(bgr, bandeira[0], bandeira[1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "draw_bandeiras(bgr)\n",
    "cv2.imshow('img', bgr)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542e1823",
   "metadata": {},
   "source": [
    "### Exercício completo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c049e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from module import ImageModule\n",
    "\n",
    "class IdentificadorBandeiras(ImageModule):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.configure_kernel(5, \"rect\")\n",
    "        self.colors = {\n",
    "            'orange': ((0, 100, 100), (20, 255, 255)),\n",
    "            'red': ((170, 100, 100), (180, 255, 255)),\n",
    "            'green': ((70, 100, 100), (80, 255, 255)),\n",
    "            'white': ((0, 0, 200), (180, 20, 255)),\n",
    "        }\n",
    "        self.bandeiras = []\n",
    "\n",
    "    def draw_bandeiras(self, bgr):\n",
    "        for bandeira in self.bandeiras:\n",
    "            cv2.rectangle(bgr, bandeira[1], bandeira[2], (255, 0, 0), 5)\n",
    "            cv2.putText(bgr, bandeira[0], bandeira[1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    def checar_bandeiras(self, hsv, rects):\n",
    "        for rect in rects:\n",
    "            x, y, w, h = rect\n",
    "            crop = hsv[y:y+h, x:x+w]\n",
    "            cv2.imshow('crop', cv2.cvtColor(crop, cv2.COLOR_HSV2BGR))\n",
    "\n",
    "            # Irlanda\n",
    "            if np.sum(self.color_filter(crop, self.colors['orange'][0], self.colors['orange'][1])) > 0:\n",
    "                self.bandeiras.append(('irlanda', (x, y), (x+w, y+h)))\n",
    "            elif np.sum(self.color_filter(crop, self.colors['green'][0], self.colors['green'][1])) > 0:\n",
    "                self.bandeiras.append(('italia', (x, y), (x+w, y+h)))\n",
    "            else:\n",
    "                area = w * h\n",
    "                print(area)\n",
    "                mask_r = self.color_filter(crop, self.colors['red'][0], self.colors['red'][1])\n",
    "                cv2.imshow('mask_r', mask_r)\n",
    "                red = np.sum(mask_r) / 255\n",
    "                mask_w = self.color_filter(crop, self.colors['white'][0], self.colors['white'][1])\n",
    "                cv2.imshow('mask_w', mask_w)\n",
    "                white = np.sum(mask_w) / 255\n",
    "                if white > red:\n",
    "                    self.bandeiras.append(('singapura', (x, y), (x+w, y+h)))\n",
    "                elif red > white:\n",
    "                    self.bandeiras.append(('peru', (x, y), (x+w, y+h)))\n",
    "                else:\n",
    "                    self.bandeiras.append(('monaco', (x, y), (x+w, y+h)))\n",
    "\n",
    "    def get_all_contours(self, bgr):\n",
    "        gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "        mask = self.color_filter(gray, 20, 255)\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        rects = []\n",
    "        for contour in contours:\n",
    "            rect = cv2.boundingRect(contour)\n",
    "            rects.append(rect)\n",
    "        \n",
    "        return bgr, rects\n",
    "\n",
    "    def run(self,bgr):\n",
    "        '''\n",
    "        Essa função deverá identificar as bandeiras na imagem passada como argumento\n",
    "        e devolver uma lista de tuplas no formato\n",
    "\n",
    "        ('pais', (x1, y1), (x2, y2))\n",
    "        '''\n",
    "        bgr,  rects = self.get_all_contours(bgr)\n",
    "        hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "        self.checar_bandeiras(hsv, rects)\n",
    "\n",
    "        bgr = self.draw_bandeiras(bgr)\n",
    "\n",
    "        return self.bandeiras\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    bgr = cv2.imread('img/teste1.png')\n",
    "    q1 = IdentificadorBandeiras()\n",
    "    items = q1.run(bgr)\n",
    "\n",
    "    print(items)\n",
    "    \n",
    "    cv2.imshow(\"Resultado\", bgr)\n",
    "    cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3871686c",
   "metadata": {},
   "source": [
    "# Módulo 6 - MobileNet e ArUco\n",
    "\n",
    "Foi feito tudo dentro da pasta `atividades_modulo_6` caso precise de qualquer arquivo é só olhar lá.\n",
    "Não consegui rodar o arquivo `atividade_3.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f9971e",
   "metadata": {},
   "source": [
    "# Módulo 7 - Controle Proporcional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea163a39",
   "metadata": {},
   "source": [
    "## Entendendo a utilização da garra\n",
    "\n",
    "A utilização da garra no nosso robô é bem simples. Para mover o ombro publique no tópico /joint1_position_controller/command uma mensagem do tipo std_msgs.Float64. * Para colocar o ombro pra cima, publique um valor de 1.5. * Para colocar o ombro pra baixo, publique um valor de -1.0. * Para colocar o ombro pra frente, publique um valor de 0.0.\n",
    "\n",
    "Para mover a garra publique no tópico /joint2_position_controller/command uma mensagem do tipo std_msgs.Float64. * Para abrir a garra, publique um valor de -1.0. * Para fechar a garra, publique um valor de 0.0.\n",
    "\n",
    "Mas tem um arquivo no my package que faz isso se quiser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcb5133",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
